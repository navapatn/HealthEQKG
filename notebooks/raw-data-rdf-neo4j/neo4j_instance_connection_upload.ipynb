{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofzwGELGdCFZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV with error handling for quotes\n",
        "input_file = \"/content/resource-neo4j_import-v2.csv\"  # Replace with your actual file name\n",
        "output_file = \"/content/resource-neo4j_import-v2-cleaned.csv\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Read CSV safely by enforcing proper delimiter handling\n",
        "df = pd.read_csv(input_file, dtype=str, engine=\"python\")\n",
        "\n",
        "# Remove problematic quotes and extra spaces\n",
        "df = df.applymap(lambda x: x.strip().replace('\"', '').replace(',', '') if isinstance(x, str) else x)\n",
        "\n",
        "# Ensure column count is correct\n",
        "expected_columns = [\"npi\", \"first_name\", \"last_name\", \"gender\", \"credential\",\n",
        "                    \"specialty\", \"facility\", \"city\", \"state\", \"zip_code\", \"year\",\"med_school\"]\n",
        "\n",
        "# Keep only expected columns\n",
        "df = df[expected_columns]\n",
        "\n",
        "# Save the cleaned CSV\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\" Cleaned CSV saved as: {output_file}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
        "\n",
        "# Count total number of records\n",
        "total_records = len(df)\n",
        "\n",
        "# Group by `grad_year` and count occurrences\n",
        "grad_year_counts = df.groupby(\"year\").size().reset_index(name=\"count\")\n",
        "\n",
        "# Display results\n",
        "print(f\"Total Records: {total_records}\")\n",
        "print(\"Records Grouped by Graduation Year:\")\n",
        "print(grad_year_counts)\n"
      ],
      "metadata": {
        "id": "K6ZuOQndoW_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[(df[\"year\"] >= 2015) & (df[\"year\"] <= 2017)]"
      ],
      "metadata": {
        "id": "47YAc8e9o8Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN values with \"UNKNOWN\" for Facility name\n",
        "df_filtered[\"facility\"].fillna(\"UNKNOWN\", inplace=True)\n",
        "df_filtered[\"city\"].fillna(\"UNKNOWN\", inplace=True)\n",
        "df_filtered[\"state\"].fillna(\"UNKNOWN\", inplace=True)\n",
        "df_filtered[\"zip_code\"].fillna(\"UNKNOWN\", inplace=True)\n",
        "\n",
        "# Drop rows where facility is still missing\n",
        "df_filtered = df_filtered[df_filtered[\"facility\"] != \"UNKNOWN\"]\n",
        "\n",
        "# Count job movements per doctor (based on unique facility entries)\n",
        "job_mobility_counts = df_filtered.groupby(\"npi\")[\"facility\"].nunique() - 1\n",
        "\n",
        "# Ensure no negative values (new doctors may have 0 moves)\n",
        "job_mobility_counts = job_mobility_counts.clip(lower=0)\n",
        "\n",
        "# Merge back to df_filtered\n",
        "df_filtered[\"job_moves\"] = df_filtered[\"npi\"].map(job_mobility_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "aSYmdoYS6GK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "IK8_BIT_mMQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "URI = \"\"\n",
        "AUTH = (\"neo4j\", \"\")\n",
        "\n",
        "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
        "    driver.verify_connectivity()"
      ],
      "metadata": {
        "id": "Ol87pfU0kX4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/resource-neo4j_import-v2-cleaned.csv\"  # Update file path\n",
        "df = pd.read_csv(CSV_PATH, dtype=str)\n",
        "\n",
        "\n",
        "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"npi\", \"facility\", \"year\", \"specialty\"])\n",
        "\n",
        "\n",
        "doctor_credentials = {\"MD\", \"DO\", \"DPM\", \"DDS\"}\n",
        "df_filtered = df[df[\"credential\"].isin(doctor_credentials)].drop_duplicates()\n",
        "\n",
        "df_filtered[\"facility\"] = df_filtered[\"facility\"].str.strip().str.lower()\n",
        "unique_facilities_df = df_filtered[[\"facility\", \"city\", \"state\", \"zip_code\"]].drop_duplicates()\n",
        "\n",
        "\n",
        "df_filtered[\"med_school\"] = df_filtered[\"med_school\"].str.strip().str.lower()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OuK_HVcXJaTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "doctor_credentials = {\"MD\", \"DO\", \"DPM\", \"DDS\"}\n",
        "\n",
        "df_filtered = df[df[\"credential\"].isin(doctor_credentials)]\n",
        "\n",
        "print(f\" Remaining Doctors in Data: {df_filtered.shape[0]}\")\n",
        "print(f\" Unique Credentials After Filtering: {df_filtered['credential'].unique()}\")\n"
      ],
      "metadata": {
        "id": "LvbB1aZWIjCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "print(f\" Unique Doctors: {df_filtered['npi'].nunique()}\")\n",
        "print(f\" Unique Facilities: {unique_facilities_df.shape[0]}\")\n",
        "\n",
        "def create_doctor(tx, row):\n",
        "    query = \"\"\"\n",
        "    MERGE (d:Doctor {npi: $npi})\n",
        "    SET d.first_name = $first_name,\n",
        "        d.last_name = $last_name,\n",
        "        d.gender = $gender,\n",
        "        d.credential = $credential,\n",
        "        d.specialty = $specialty;\n",
        "    \"\"\"\n",
        "    tx.run(query,\n",
        "           npi=row[\"npi\"], first_name=row[\"first_name\"],\n",
        "           last_name=row[\"last_name\"], gender=row[\"gender\"],\n",
        "           credential=row[\"credential\"], specialty=row[\"specialty\"])\n",
        "\n",
        "def create_facility(tx, row):\n",
        "    query = \"\"\"\n",
        "    MERGE (f:Facility {name: $facility})\n",
        "    SET f.city = COALESCE($city, \"UNKNOWN\"),\n",
        "        f.state = COALESCE($state, \"UNKNOWN\"),\n",
        "        f.zip_code = COALESCE($zip_code, \"UNKNOWN\");\n",
        "    \"\"\"\n",
        "    tx.run(query,\n",
        "           facility=row[\"facility\"], city=row[\"city\"],\n",
        "           state=row[\"state\"], zip_code=row[\"zip_code\"])\n",
        "\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Inserting Doctor nodes into Neo4j...\")\n",
        "    for index, row in tqdm(df_filtered.drop_duplicates(subset=[\"npi\"]).iterrows(), total=df_filtered[\"npi\"].nunique(), desc=\"Processing Doctors\"):\n",
        "        session.execute_write(create_doctor, row)\n",
        "\n",
        "print(\" Doctor nodes successfully added to Neo4j!\")\n",
        "\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Inserting Facility nodes into Neo4j...\")\n",
        "    for index, row in tqdm(unique_facilities_df.iterrows(), total=unique_facilities_df.shape[0], desc=\"Processing Facilities\"):\n",
        "        session.execute_write(create_facility, row)\n",
        "\n",
        "print(\" Facility nodes successfully added to Neo4j!\")"
      ],
      "metadata": {
        "id": "6aOOWlUTJQwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_doctor_grad_year(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (d:Doctor {npi: $npi})\n",
        "    SET d.grad_year = toInteger($grad_year)\n",
        "    \"\"\"\n",
        "    tx.run(query, npi=row[\"npi\"], grad_year=row[\"year\"])\n",
        "\n",
        "\n",
        "df_grad_year = df_filtered[[\"npi\", \"year\"]].dropna().drop_duplicates()\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Updating Doctor nodes with graduation year...\")\n",
        "    for _, row in tqdm(df_grad_year.iterrows(), total=df_grad_year.shape[0], desc=\"Adding grad_year\"):\n",
        "        session.execute_write(update_doctor_grad_year, row)\n",
        "\n",
        "print(\" Graduation years successfully updated!\")\n"
      ],
      "metadata": {
        "id": "Q8LhOUBmRuie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def update_doctor_grad_year(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (d:Doctor {npi: $npi})\n",
        "    SET d.grad_year = toInteger($grad_year)\n",
        "    \"\"\"\n",
        "    tx.run(query, npi=row[\"npi\"], grad_year=row[\"year\"])\n",
        "\n",
        "df_grad_year = df_filtered[[\"npi\", \"year\"]].dropna().drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "start_index = 58112\n",
        "df_resume = df_grad_year.iloc[start_index:]\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(f\" Resuming Doctor grad_year updates from index {start_index}...\")\n",
        "    for idx, row in tqdm(df_resume.iterrows(), total=len(df_resume), desc=\"Resuming grad_year\"):\n",
        "        session.execute_write(update_doctor_grad_year, row)\n",
        "\n",
        "print(\" Remaining grad_year updates completed!\")\n"
      ],
      "metadata": {
        "id": "C8BeuD_i09Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique medical schools\n",
        "unique_med_schools_df = df_filtered[[\"med_school\"]].drop_duplicates()\n",
        "\n",
        "# Print summary\n",
        "print(f\" Unique Medical Schools: {unique_med_schools_df.shape[0]}\")\n",
        "\n",
        "def create_medical_school(tx, row):\n",
        "    query = \"\"\"\n",
        "    MERGE (m:MedicalSchool {name: $med_school});\n",
        "    \"\"\"\n",
        "    tx.run(query, med_school=row[\"med_school\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0HU9SzvlT9nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure year is numeric and drop NaN values\n",
        "df_filtered[\"year\"] = pd.to_numeric(df_filtered[\"year\"], errors=\"coerce\")\n",
        "df_filtered = df_filtered.dropna(subset=[\"year\", \"specialty\"])\n",
        "\n",
        "# Extract unique years\n",
        "unique_years_df = df_filtered[[\"year\"]].drop_duplicates()\n",
        "\n",
        "# Extract unique job placements (year + specialty)\n",
        "unique_job_placements_df = df_filtered[[\"year\", \"specialty\"]].drop_duplicates()\n",
        "\n",
        "# Print summary\n",
        "print(f\" Unique Years: {unique_years_df.shape[0]}\")\n",
        "print(f\" Unique Job Placements: {unique_job_placements_df.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "NGvpFqxtqG1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_year(tx, row):\n",
        "    query = \"\"\"\n",
        "    MERGE (y:Year {value: $year});\n",
        "    \"\"\"\n",
        "    tx.run(query, year=row[\"year\"])\n",
        "\n",
        "def create_job_placement(tx, row):\n",
        "    query = \"\"\"\n",
        "    MERGE (j:JobPlacement {year: $year, specialty: $specialty});\n",
        "    \"\"\"\n",
        "    tx.run(query, year=row[\"year\"], specialty=row[\"specialty\"])\n",
        "\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Inserting Year nodes into Neo4j...\")\n",
        "    for index, row in tqdm(unique_years_df.iterrows(), total=unique_years_df.shape[0], desc=\"Processing Years\"):\n",
        "        session.execute_write(create_year, row)\n",
        "\n",
        "print(\" Year nodes successfully added to Neo4j!\")\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Inserting JobPlacement nodes into Neo4j...\")\n",
        "    for index, row in tqdm(unique_job_placements_df.iterrows(), total=unique_job_placements_df.shape[0], desc=\"Processing JobPlacements\"):\n",
        "        session.execute_write(create_job_placement, row)\n",
        "\n",
        "print(\" JobPlacement nodes successfully added to Neo4j!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pTB6lwphqVKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SjXdSZ71E2ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relationships\n"
      ],
      "metadata": {
        "id": "Buu-2sR9EzVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_works_at_df = df_filtered[[\"npi\", \"facility\"]].drop_duplicates()\n",
        "unique_has_participant_df = df_filtered[[\"npi\", \"year\", \"specialty\"]].drop_duplicates()\n",
        "unique_happens_at_df = df_filtered[[\"year\", \"specialty\", \"facility\"]].drop_duplicates()\n",
        "unique_has_time_reference_df = df_filtered[[\"year\", \"specialty\"]].drop_duplicates()\n",
        "\n",
        "job_mobility_counts = df_filtered.groupby(\"npi\")[\"facility\"].nunique() - 1\n",
        "job_mobility_counts = job_mobility_counts.clip(lower=0)  # Ensure no negatives\n",
        "df_filtered[\"job_moves\"] = df_filtered[\"npi\"].map(job_mobility_counts)\n",
        "unique_has_mobility_df = df_filtered[[\"npi\", \"job_moves\"]].drop_duplicates()\n",
        "\n",
        "print(f\" WORKS_AT Relationships: {unique_works_at_df.shape[0]}\")\n",
        "print(f\" HAS_PARTICIPANT Relationships: {unique_has_participant_df.shape[0]}\")\n",
        "print(f\" HAPPENS_AT Relationships: {unique_happens_at_df.shape[0]}\")\n",
        "print(f\" HAS_TIME_REFERENCE Relationships: {unique_has_time_reference_df.shape[0]}\")\n",
        "print(f\" HAS_MOBILITY Relationships: {unique_has_mobility_df.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "cUeQDEpcqjjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def link_doctor_to_facility(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (d:Doctor {npi: $npi})\n",
        "    MATCH (f:Facility)\n",
        "    WHERE toLower(f.name) = toLower($facility)\n",
        "    MERGE (d)-[:WORKS_AT]->(f);\n",
        "    \"\"\"\n",
        "    tx.run(query, npi=row[\"npi\"], facility=row[\"facility\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def link_doctor_to_jobplacement(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (d:Doctor {npi: $npi})\n",
        "    MATCH (j:JobPlacement)\n",
        "    WHERE j.year = $year AND toUpper(j.specialty) = toUpper($specialty)\n",
        "    MERGE (d)-[:HAS_PARTICIPANT]->(j);\n",
        "    \"\"\"\n",
        "    tx.run(query, npi=row[\"npi\"], year=row[\"year\"], specialty=row[\"specialty\"])\n",
        "\n",
        "\n",
        "def link_jobplacement_to_facility(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (j:JobPlacement)\n",
        "    WHERE j.year = $year AND toUpper(j.specialty) = toUpper($specialty)\n",
        "    MATCH (f:Facility)\n",
        "    WHERE toLower(f.name) = toLower($facility)\n",
        "    MERGE (j)-[:HAPPENS_AT]->(f);\n",
        "    \"\"\"\n",
        "    tx.run(query, year=row[\"year\"], specialty=row[\"specialty\"], facility=row[\"facility\"])\n",
        "\n",
        "\n",
        "def link_jobplacement_to_year(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (j:JobPlacement)\n",
        "    WHERE j.year = $year AND toUpper(j.specialty) = toUpper($specialty)\n",
        "    MATCH (y:Year {value: $year})\n",
        "    MERGE (j)-[:HAS_TIME_REFERENCE]->(y);\n",
        "    \"\"\"\n",
        "    tx.run(query, year=row[\"year\"], specialty=row[\"specialty\"])\n",
        "\n",
        "\n",
        "def link_doctor_to_medical_school(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (d:Doctor {npi: $npi})\n",
        "    MATCH (m:MedicalSchool)\n",
        "    WHERE toLower(m.name) = toLower($med_school)\n",
        "    MERGE (d)-[:GRADUATED_FROM]->(m);\n",
        "    \"\"\"\n",
        "    tx.run(query, npi=row[\"npi\"], med_school=row[\"med_school\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZFRR8ZWqzuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Creating WORKS_AT relationships...\")\n",
        "    for index, row in tqdm(unique_works_at_df.iterrows(), total=unique_works_at_df.shape[0], desc=\"Processing WORKS_AT\"):\n",
        "        session.execute_write(link_doctor_to_facility, row)\n",
        "\n",
        "print(\" WORKS_AT relationships successfully added to Neo4j!\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l8ZcTjiWq9CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Creating HAS_PARTICIPANT relationships...\")\n",
        "    for index, row in tqdm(unique_has_participant_df.iterrows(), total=unique_has_participant_df.shape[0], desc=\"Processing HAS_PARTICIPANT\"):\n",
        "        session.execute_write(link_doctor_to_jobplacement, row)\n",
        "\n",
        "print(\" HAS_PARTICIPANT relationships successfully added to Neo4j!\")"
      ],
      "metadata": {
        "id": "YIEy95_lq-r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with driver.session() as session:\n",
        "    print(\" Creating MedicalSchool nodes...\")\n",
        "    for index, row in tqdm(unique_med_schools_df.iterrows(), total=unique_med_schools_df.shape[0], desc=\"Processing Medical Schools\"):\n",
        "        session.execute_write(create_medical_school, row)\n",
        "\n",
        "print(\" MedicalSchool nodes successfully added to Neo4j!\")"
      ],
      "metadata": {
        "id": "FNuI8H-3v6Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 Insert HAPPENS_AT Relationships\n",
        "with driver.session() as session:\n",
        "    print(\" Creating HAPPENS_AT relationships...\")\n",
        "    for index, row in tqdm(unique_happens_at_df.iterrows(), total=unique_happens_at_df.shape[0], desc=\"Processing HAPPENS_AT\"):\n",
        "        session.execute_write(link_jobplacement_to_facility, row)\n",
        "\n",
        "print(\" HAPPENS_AT relationships successfully added to Neo4j!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r_dFTAzEq_15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with driver.session() as session:\n",
        "    print(\" Creating HAS_TIME_REFERENCE relationships...\")\n",
        "    for index, row in tqdm(unique_has_time_reference_df.iterrows(), total=unique_has_time_reference_df.shape[0], desc=\"Processing HAS_TIME_REFERENCE\"):\n",
        "        session.execute_write(link_jobplacement_to_year, row)\n",
        "\n",
        "print(\" HAS_TIME_REFERENCE relationships successfully added to Neo4j!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yEpulybvrA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Import tqdm for tracking\n",
        "\n",
        "with driver.session() as session:\n",
        "    print(\" Creating GRADUATED_FROM relationships...\")\n",
        "    for index, row in tqdm(df_filtered[[\"npi\", \"med_school\"]].drop_duplicates().iterrows(), total=df_filtered[[\"npi\", \"med_school\"]].drop_duplicates().shape[0], desc=\"Processing GRADUATED_FROM\"):\n",
        "        session.execute_write(link_doctor_to_medical_school, row)\n",
        "\n",
        "print(\" GRADUATED_FROM relationships successfully added to Neo4j!\")\n"
      ],
      "metadata": {
        "id": "-X2RPRxYUPtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load ADI data\n",
        "adi_df = pd.read_csv(\"/content/medical_doctors_with_ADI.csv\", dtype=str)\n",
        "\n",
        "# Standardize ZIP codes to 5-digit format\n",
        "adi_df['5_digit_zip_code'] = adi_df['ZIP_Code_5_Digit_Standardized'].astype(str).str.zfill(5)\n",
        "\n",
        "# Convert numeric fields to float\n",
        "adi_df['adi_nat_2015'] = adi_df['Avg_ADI_NATRANK_2015'].astype(float)\n",
        "adi_df['adi_state_2015'] = adi_df['Avg_ADI_STATERNK_2015'].astype(float)\n",
        "adi_df['adi_nat_2020'] = adi_df['Avg_ADI_NATRANK_2020'].astype(float)\n",
        "adi_df['adi_state_2020'] = adi_df['Avg_ADI_STATERNK_2020'].astype(float)\n",
        "adi_df['gisjoin_2015'] = adi_df['GISJOIN_2015']\n",
        "adi_df['gisjoin_2020'] = adi_df['GISJOIN_2020']\n",
        "\n",
        "# Extract unique ADI scores by ZIP\n",
        "adi_by_zip = adi_df.groupby(\"5_digit_zip_code\").agg({\n",
        "    'adi_nat_2015': 'mean',\n",
        "    'adi_state_2015': 'mean',\n",
        "    'adi_nat_2020': 'mean',\n",
        "    'adi_state_2020': 'mean',\n",
        "    'gisjoin_2015': 'first',\n",
        "    'gisjoin_2020': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "print(f\" Extracted {len(adi_by_zip)} unique ZIP code ADI entries.\")\n",
        "\n",
        "# Standardize ZIP in df_filtered\n",
        "df_filtered['5_digit_zip_code'] = df_filtered['zip_code'].astype(str).str[:5].str.zfill(5)\n",
        "\n",
        "# Merge ADI data into your main dataframe\n",
        "df_filtered = df_filtered.merge(adi_by_zip, on='5_digit_zip_code', how='left')\n",
        "\n",
        "print(\" ADI scores merged into df_filtered!\")\n"
      ],
      "metadata": {
        "id": "HCy3NcwhrCHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Prepare a unique list of facilities with ADI by 5-digit ZIP code\n",
        "facility_adi = df_filtered[[\n",
        "    \"facility\", \"city\", \"state\", \"5_digit_zip_code\",\n",
        "    \"adi_nat_2015\", \"adi_state_2015\",\n",
        "    \"adi_nat_2020\", \"adi_state_2020\"\n",
        "]].drop_duplicates()\n",
        "\n",
        "# Define a function to update the facility node in Neo4j\n",
        "def update_facility_adi(tx, row):\n",
        "    query = \"\"\"\n",
        "    MATCH (f:Facility)\n",
        "    WHERE toLower(f.name) = toLower($facility)\n",
        "      AND toLower(f.city) = toLower($city)\n",
        "      AND f.state = $state\n",
        "      AND f.zip_code STARTS WITH $zip\n",
        "    SET f.adi_nat_2015 = $adi_nat_2015,\n",
        "        f.adi_state_2015 = $adi_state_2015,\n",
        "        f.adi_nat_2020 = $adi_nat_2020,\n",
        "        f.adi_state_2020 = $adi_state_2020;\n",
        "    \"\"\"\n",
        "    tx.run(query,\n",
        "           facility=row[\"facility\"],\n",
        "           city=row[\"city\"],\n",
        "           state=row[\"state\"],\n",
        "           zip=row[\"5_digit_zip_code\"],\n",
        "           adi_nat_2015=row[\"adi_nat_2015\"],\n",
        "           adi_state_2015=row[\"adi_state_2015\"],\n",
        "           adi_nat_2020=row[\"adi_nat_2020\"],\n",
        "           adi_state_2020=row[\"adi_state_2020\"])\n",
        "\n",
        "# Push the updates to Neo4j\n",
        "with driver.session() as session:\n",
        "    print(\" Updating Facility nodes with ADI scores...\")\n",
        "    for _, row in tqdm(facility_adi.iterrows(), total=facility_adi.shape[0]):\n",
        "        session.execute_write(update_facility_adi, row)\n",
        "\n",
        "print(\" ADI scores successfully updated for Facility nodes in Neo4j!\")\n"
      ],
      "metadata": {
        "id": "xONL9ZgxvPI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MATCH (f:Facility)\n",
        "# WHERE toString(f.adi_nat_2015) = \"NaN\"\n",
        "#    OR toString(f.adi_state_2015) = \"NaN\"\n",
        "#    OR toString(f.adi_nat_2020) = \"NaN\"\n",
        "#    OR toString(f.adi_state_2020) = \"NaN\"\n",
        "# SET f.adi_nat_2015 = CASE WHEN toString(f.adi_nat_2015) = \"NaN\" THEN NULL ELSE f.adi_nat_2015 END,\n",
        "#     f.adi_state_2015 = CASE WHEN toString(f.adi_state_2015) = \"NaN\" THEN NULL ELSE f.adi_state_2015 END,\n",
        "#     f.adi_nat_2020 = CASE WHEN toString(f.adi_nat_2020) = \"NaN\" THEN NULL ELSE f.adi_nat_2020 END,\n",
        "#     f.adi_state_2020 = CASE WHEN toString(f.adi_state_2020) = \"NaN\" THEN NULL ELSE f.adi_state_2020 END;\n"
      ],
      "metadata": {
        "id": "_b5j4bjV76-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}